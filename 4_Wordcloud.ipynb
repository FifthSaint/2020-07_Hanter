{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 워드클라우드(말구름) 그리기\n",
    "이번에는 자신의 관심 주제에 대한 기사 텍스트 데이터를 **빅카인즈**에서 다운받아<br>\n",
    "실제 가장 많이 등장하는 단어 비중에 따른 워드클라우드를 그려보겠습니다<br>\n",
    "<br>\n",
    "우선 [빅카인즈](https://www.bigkinds.or.kr/)에서 회원 가입<br>\n",
    "이후 검색창에 관심 단어를 넣고 최근 3개월의 검색 결과를 봅니다<br>\n",
    "그리고 다운로드하여 현 작업 폴더로 파일을 옮겨 놓습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 이번 작업에 필요한 라이브러리들입니다<br>\n",
    "**라이브러리? 미리 만들어둔 함수 등을 모아놓은 도서관"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "글자와 색 지정<br>\n",
    "** 내용이 무엇인지 아실 필요는 전혀 없으나 '변수'의 쓰임에 대해서 눈여겨 보시길"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Font setting\n",
    "font_path = 'C:\\\\Windows\\\\Fonts\\\\H2GTRE.TTF'\n",
    "\n",
    "# Colormap\n",
    "cmap_B = plt.cm.GnBu(np.linspace(0,1,20))\n",
    "cmap_B = mpl.colors.ListedColormap(cmap_B[3:,:-1])\n",
    "\n",
    "cmap_R = mpl.pyplot.cm.YlOrRd(np.linspace(0,1,20))\n",
    "cmap_R = mpl.colors.ListedColormap(cmap_R[5:,:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "File='NewsResult_20200429-20200729.xlsx' #빅카인즈에서 다운받은 실제 파일이름에 맞게\n",
    "\n",
    "df = pd.read_excel(File) #파일 읽기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다룰 데이터에 대해 먼저 살펴보겠습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "워드클라우드로 그리고자 하는 데이터는 15번째 '키워드' 열에 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df.values.T.tolist()[14] #15번째 열을 읽어들임. 0부터 카운트하기 때문에 14임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리\n",
    "빅카인즈 데이터의 장점 가운데 하나는 토큰화 과정을 마친 명사 데이터(키워드)를 제공한다는 점입니다<br>\n",
    "그러나 자연어처리에선 이 외에도 여러 전처리 과정이 필요합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 자료형의 확인\n",
    "이 부분은 중요하지만 핵심만 짚고 넘어가겠습니다. <br>\n",
    "엑셀에서 이야기했던 데이터의 종류-명목형(문자)과 연속형(숫자)-에 대해서 상기해 주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(texts[0]) #각 데이터가 하나의 긴 str 데이터임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = [str(x).split(',') for x in texts] #각각 나눠줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(terms[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모두 하나의 Pool로 합침 <br>\n",
    ".extend라는 표현(메소드, 일종의 함수)에 유의해 주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms1 = list()\n",
    "for each_terms in terms:\n",
    "    terms1.extend(each_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체 명사의 갯수는? ('함수'를 상기해 주세요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(terms1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한 글자 단어와 영단어는 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "ref_terms = [x for x in terms1 if (len(str(x))>1) and not re.match(r'[A-Za-z]+',str(x))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 제거하고 싶은 단어: 불용어 stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords v1.0\n",
    "stopwords = ['들이', '하면', '해서','생각','하지','하기','경우','그거','하게','정도',\n",
    "             '시간','어디','올해','이거','하나','어디','진짜','때문','해도','사실',\n",
    "             '이유','하루','작년','진짜','자신','이번','이상','한거','전화','시작',\n",
    "             '자체','우리','단어','설명', '바보', '당선인']\n",
    "ref_terms1 = [str(x) for x in ref_terms if x not in stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정규화(normalize)\n",
    "\n",
    "그리고 이번 과정에서는 시간상 건너뜁니다만 정규화(normalization) 과정도 매우 중요합니다<br>\n",
    "정규화는 같은 단어로 구분되어야 할 여러 단어를 묶어 주는 것을 말합니다<br>\n",
    "예컨대 '기계학습'과 '기계 학습'이 구분되어 있다면(후자의 경우 '기계'와 '학습'이라는 두 단어로 토큰화 될 가능성이 높겠지요)<br>\n",
    "기계학습의 빈도는 실제에 비해 작게 나올 위험이 있습니다. 이런 것들을 잡아주는 것을 말합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 빈도 테이블로 바꿔주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "freq1 = collections.Counter(ref_terms1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "빈도 테이블 데이터를 살펴보겠습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "빈도가 높은 순으로 정렬하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_freq1 = sorted(freq1.items(), key=lambda item: item[1], reverse=True)\n",
    "dict_freq1 = {x[0]:x[1] for x in sorted_freq1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 말구름 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_freq1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drawing wordcloud\n",
    "wordcloud = WordCloud(font_path=font_path,\n",
    "                      max_words=150,\n",
    "                      colormap=cmap_R, # color\n",
    "                      stopwords=stopwords,\n",
    "                      background_color='white',\n",
    "                     width=1000, height=1000).generate_from_frequencies(dict_freq1)\n",
    "\n",
    "mpl.pyplot.figure(figsize=(10,10))\n",
    "mpl.pyplot.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "mpl.pyplot.axis(\"off\")\n",
    "mpl.pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
